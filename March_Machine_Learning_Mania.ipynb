{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9XiC1op1jutjWN15RPlpT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KyPython/March-Machine-Learning-Mania/blob/main/March_Machine_Learning_Mania.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model training"
      ],
      "metadata": {
        "id": "WjEOklY1ko_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "MRICPICz3o5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # No need to remount\n",
        "\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split  # Import for data splitting\n",
        "\n",
        "\n",
        "def predict_tournament_results(X_train, y_train, X_test, team_ids):\n",
        "    \"\"\"\n",
        "    Predicts the results of the tournament based on the provided data and model.\n",
        "\n",
        "    Args:\n",
        "        X_train (pd.DataFrame): Training data features.\n",
        "        y_train (pd.Series): Training data target.\n",
        "        X_test (pd.DataFrame): Test data features.\n",
        "        team_ids (list): List of team IDs.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are team IDs (int) and values are\n",
        "              predicted probabilities (float) of winning against any other team.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a pipeline with scaling and logistic regression\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('logistic', LogisticRegression(solver='liblinear', penalty='l2'))\n",
        "    ])\n",
        "\n",
        "    # Calibrate the model\n",
        "    # Inside the predict_tournament_results function:\n",
        "calibrated_model = CalibratedClassifierCV(pipeline, method='isotonic', cv=3) # Reduced cv to 3\n",
        "\n",
        "    # Train the calibrated model\n",
        "    calibrated_model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict probabilities for test data\n",
        "    probabilities = calibrated_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Create a dictionary of team win probabilities\n",
        "    team_win_probs = dict(zip(team_ids, probabilities))\n",
        "\n",
        "    return team_win_probs\n",
        "\n",
        "\n",
        "# Load data for both Men's and Women's tournaments\n",
        "mens_regular_season_path = '/content/drive/MyDrive/March_Madness/MRegularSeasonDetailedResults.csv'\n",
        "mens_data = pd.read_csv(mens_regular_season_path)\n",
        "\n",
        "womens_regular_season_path = '/content/drive/MyDrive/March_Madness/WRegularSeasonDetailedResults.csv'\n",
        "womens_data = pd.read_csv(womens_regular_season_path)\n",
        "\n",
        "# --- Perform feature engineering and create X, y for Men's ---\n",
        "# Feature Engineering for Men's\n",
        "mens_data['ScoreDiff'] = mens_data['WScore'] - mens_data['LScore']  # Create a feature: score difference\n",
        "X_men = mens_data[['ScoreDiff']]  # Use score difference as a feature\n",
        "y_men = mens_data['WTeamID']  # Target variable: winning team ID\n",
        "X_train_men, X_test_men, y_train_men, y_test_men = train_test_split(X_men, y_men, test_size=0.2, random_state=42)  # Split data\n",
        "team_ids_men = mens_data['WTeamID'].unique()  # Get unique team IDs\n",
        "\n",
        "# --- Perform feature engineering and create X, y for Women's ---\n",
        "# Feature Engineering for Women's\n",
        "womens_data['ScoreDiff'] = womens_data['WScore'] - womens_data['LScore']  # Create a feature: score difference\n",
        "X_women = womens_data[['ScoreDiff']]  # Use score difference as a feature\n",
        "y_women = womens_data['WTeamID']  # Target variable: winning team ID\n",
        "X_train_women, X_test_women, y_train_women, y_test_women = train_test_split(X_women, y_women, test_size=0.2, random_state=42)  # Split data\n",
        "team_ids_women = womens_data['WTeamID'].unique()  # Get unique team IDs\n",
        "\n",
        "# Train models and get predictions\n",
        "team_win_probs_men = predict_tournament_results(X_train_men, y_train_men, X_test_men, team_ids_men)\n",
        "team_win_probs_women = predict_tournament_results(X_train_women, y_train_women, X_test_women, team_ids_women)\n",
        "\n",
        "\n",
        "def create_submission_file_2025(predictions_dict_men, predictions_dict_women, output_file='submission.csv', season=2025):\n",
        "    \"\"\"\n",
        "    Creates a submission file for the 2025 NCAA tournament prediction competition\n",
        "    for both Men's and Women's tournaments.\n",
        "\n",
        "    Args:\n",
        "        predictions_dict_men (dict): Predictions for Men's games.\n",
        "        predictions_dict_women (dict): Predictions for Women's games.\n",
        "        output_file (str): Name of the output CSV file.\n",
        "        season (int): The season year.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load MTeams.csv and WTeams.csv to get all team IDs\n",
        "    mteams_path = '/content/drive/MyDrive/March_Madness/MTeams.csv'\n",
        "    mteams_df = pd.read_csv(mteams_path)\n",
        "    men_team_ids = mteams_df['TeamID'].unique()\n",
        "\n",
        "    wteams_path = '/content/drive/MyDrive/March_Madness/WTeams.csv'\n",
        "    wteams_df = pd.read_csv(wteams_path)\n",
        "    women_team_ids = wteams_df['TeamID'].unique()\n",
        "\n",
        "    # Generate all possible matchups for Men's and Women's\n",
        "    men_matchups = list(itertools.combinations(men_team_ids, 2))\n",
        "    women_matchups = list(itertools.combinations(women_team_ids, 2))\n",
        "\n",
        "    # Create submission DataFrame\n",
        "    submission_data = []\n",
        "\n",
        "    # Add Men's predictions\n",
        "    for team1, team2 in men_matchups:\n",
        "        id_str = f\"{season}_{min(team1, team2)}_{max(team1, team2)}\"\n",
        "        pred = predictions_dict_men.get(min(team1, team2), 0.5)\n",
        "        submission_data.append([id_str, pred])\n",
        "\n",
        "    # Add Women's predictions\n",
        "    for team1, team2 in women_matchups:\n",
        "        id_str = f\"{season}_{min(team1, team2)}_{max(team1, team2)}\"\n",
        "        pred = predictions_dict_women.get(min(team1, team2), 0.5)\n",
        "        submission_data.append([id_str, pred])\n",
        "\n",
        "    submission_df = pd.DataFrame(submission_data, columns=['ID', 'Pred'])\n",
        "\n",
        "    # Save to CSV\n",
        "    submission_df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\"Submission file saved to: {output_file}\")\n",
        "\n",
        "# Create submission file\n",
        "create_submission_file_2025(team_win_probs_men, team_win_probs_women, output_file='submission_2025.csv')"
      ],
      "metadata": {
        "id": "9JkndIONkpTc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1746e56c-63b5-4332-b9f6-61d66e42fda9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-8-e847bafdb6ba>, line 39)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-e847bafdb6ba>\"\u001b[0;36m, line \u001b[0;32m39\u001b[0m\n\u001b[0;31m    calibrated_model.fit(X_train, y_train)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "NnISILpk3fuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming X and y are defined from your previous data loading and feature engineering\n",
        "# For example, if using the Men's data:\n",
        "# X = X_men\n",
        "# y = y_men\n",
        "\n",
        "# OR if using the Women's data:\n",
        "# X = X_women\n",
        "# y = y_women\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Calibrate the model\n",
        "calibrated_rf = CalibratedClassifierCV(rf_model, method='isotonic', cv=5)\n",
        "\n",
        "# Train the calibrated model\n",
        "calibrated_rf.fit(X_train, y_train)  # Now X_train and y_train are defined\n",
        "\n",
        "# Predict probabilities\n",
        "probabilities = calibrated_rf.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "id": "xG2GUutG3gF4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "a4946fd8-abbb-4f68-d7a5-4d22f4134dc6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-cba045cc9298>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Split the data into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Create a Random Forest model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting Machines"
      ],
      "metadata": {
        "id": "SXSdXxbZ3zEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# Assuming X_train, y_train, X_test are defined\n",
        "\n",
        "# Create a LightGBM model\n",
        "lgbm_model = lgb.LGBMClassifier(objective='binary', random_state=42)\n",
        "\n",
        "# Calibrate the model\n",
        "calibrated_lgbm = CalibratedClassifierCV(lgbm_model, method='isotonic', cv=5)\n",
        "\n",
        "# Train the calibrated model\n",
        "calibrated_lgbm.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "probabilities = calibrated_lgbm.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "id": "5CX2Z5DH3zbq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "9855b0b0-027e-47f8-dc92-79a42d8ffd9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ab6cfb8796b6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Train the calibrated model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcalibrated_lgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Predict probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search CV (LightGBM)"
      ],
      "metadata": {
        "id": "vOx-_1hK4LmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import brier_score_loss\n",
        "\n",
        "brier_scorer = make_scorer(brier_score_loss, greater_is_better=False) #Brier score loss must be minimized.\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, scoring=brier_scorer, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "kuObWeRq4L-t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "379bdc1b-bd23-4c69-a514-4f91682b66b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-750c079c8f09>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbrier_scorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Fold Time Series Split"
      ],
      "metadata": {
        "id": "WT4ImcLu4Reb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import brier_score_loss\n",
        "from sklearn.metrics import make_scorer\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X, y are your features and target\n",
        "tscv = TimeSeriesSplit(n_splits=5) # Adjust n_splits as needed\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "brier_scorer = make_scorer(brier_score_loss, greater_is_better=False)\n",
        "brier_scores = []\n",
        "\n",
        "for train_index, test_index in tscv.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict_proba(X_test)[:,1]\n",
        "    brier = brier_score_loss(y_test, y_pred)\n",
        "    brier_scores.append(brier)\n",
        "\n",
        "print(f\"Brier Scores: {brier_scores}\")\n",
        "print(f\"Mean Brier Score: {np.mean(brier_scores)}\")"
      ],
      "metadata": {
        "id": "bDy003Ks4R0N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "554eb5fd-8a19-480e-c979-9d2b4bb1c2ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-750620339453>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mbrier_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtscv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calibrated Classifier"
      ],
      "metadata": {
        "id": "DaaTRAUq4fux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming X, y are defined\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a base model (e.g., Random Forest)\n",
        "base_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Calibrate the model using CalibratedClassifierCV\n",
        "calibrated_model = CalibratedClassifierCV(base_model, method='isotonic', cv=5) #Or method='platt'\n",
        "\n",
        "# Train the calibrated model\n",
        "calibrated_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict calibrated probabilities\n",
        "calibrated_probabilities = calibrated_model.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "id": "p__slBEE4gKe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "69c272c1-429f-4f7e-f1c0-ccf20905dfb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6ed23fa9f837>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Assuming X, y are defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Create a base model (e.g., Random Forest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission"
      ],
      "metadata": {
        "id": "OHLC33y0hJ9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "def create_submission_file_2025(predictions_dict, output_file='submission.csv', season=2025):\n",
        "    \"\"\"\n",
        "    Creates a submission file for the 2025 NCAA tournament prediction competition.\n",
        "\n",
        "    Args:\n",
        "        predictions_dict (dict): A dictionary where keys are team IDs (int) and\n",
        "                                  values are predicted probabilities (float)\n",
        "                                  of winning against any other team.\n",
        "        output_file (str): Name of the output CSV file. Defaults to 'submission.csv'.\n",
        "        season (int): The season year (defaults to 2025).\n",
        "    \"\"\"\n",
        "\n",
        "    # Get all unique team IDs\n",
        "    team_ids = list(predictions_dict.keys())\n",
        "\n",
        "    # Generate all possible matchups\n",
        "    matchups = list(itertools.combinations(team_ids, 2))\n",
        "\n",
        "    # Create submission DataFrame\n",
        "    submission_data = []\n",
        "    for team1, team2 in matchups:\n",
        "        # Create ID\n",
        "        id_str = f\"{season}_{min(team1, team2)}_{max(team1, team2)}\"\n",
        "\n",
        "        # Get prediction (probability of lower-ID team winning)\n",
        "        pred = predictions_dict[min(team1, team2)]  # Replace with your actual prediction logic\n",
        "\n",
        "        submission_data.append([id_str, pred])\n",
        "\n",
        "    submission_df = pd.DataFrame(submission_data, columns=['ID', 'Pred'])\n",
        "\n",
        "    # Save to CSV\n",
        "    submission_df.to_csv(output_file, index=False)\n",
        "\n",
        "    print(f\"Submission file saved to: {output_file}\")\n",
        "\n",
        "# Example usage (replace with your actual prediction logic)\n",
        "# Assume you have a dictionary 'team_win_probs' with predicted win probabilities for each team\n",
        "team_win_probs = {\n",
        "    1101: 0.6,\n",
        "    1102: 0.55,\n",
        "    1103: 0.48,\n",
        "    # ... (add more teams and their win probabilities) ...\n",
        "}\n",
        "\n",
        "# Create the submission file\n",
        "create_submission_file_2025(team_win_probs, output_file='submission_2025.csv')"
      ],
      "metadata": {
        "id": "ZNNexh4yhJu2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}